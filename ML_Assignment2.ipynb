{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafelsiregar/imagemlp/blob/master/ML_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hyjFmoURfm4"
      },
      "source": [
        "# Multilayer Perceptron from scratch\n",
        "\n",
        "Referensi dari video bu Afia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNRGr1V-L8kM"
      },
      "source": [
        "from random import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.utils import shuffle\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1DZWkSHuPxs"
      },
      "source": [
        "##Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLiihXTDMl2n"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1.0 / (1.0+math.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPxLQKezQTBs"
      },
      "source": [
        "def mse(output, target):\n",
        "  err = 0\n",
        "  for outp, targ in zip(output, target):\n",
        "    err += 1/2 * (outp - targ)**2\n",
        "  return err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15EnT2s2Rkrs"
      },
      "source": [
        "##class Network \n",
        "Berisi 3 layer: input, hidden dan output. Tiap layer berisi neuron yang berisi:\n",
        "- `weights`: array np berisi weight tiap neuron dari layer sebelumnya ke dirinya\n",
        "- `bias`  : nilai bias untuk neuron ini, dipakai untuk menghitung nilai aktivasi\n",
        "- `output`: nilai output untuk neuron ini, yaitu nilai aktivasinya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzU9QaaSRcYO"
      },
      "source": [
        "class Network:\n",
        "  def __init__(self, inp_n = 0, hid_n = 0, out_n = 0):\n",
        "    self.shape = {'input': inp_n, 'hidden': hid_n, 'output': out_n}\n",
        "    self.layers = [\n",
        "                  # hidden layer\n",
        "                  [{\n",
        "                      'weights' : np.array([random() for i in range(inp_n)]),\n",
        "                      'bias'    : random(),\n",
        "                      'output'  : 0\n",
        "                  } for j in range(hid_n)],\n",
        "                   \n",
        "                  # output layer\n",
        "                  [{\n",
        "                      'weights' : np.array([random() for i in range(hid_n)]),\n",
        "                      'bias'    : random(),\n",
        "                      'output'  : 0\n",
        "                  } for j in range(out_n)]\n",
        "    ]\n",
        "  \n",
        " \n",
        "  # Forward propagate\n",
        "  # Tiap neuron di hidden dihitung aktivasinya, kemudian dibawa ke output layer\n",
        "  # Return sebuah array berisi aktivasi dari tiap neuron output layer\n",
        "  def forward(self, data):\n",
        "    # Input ke hidden\n",
        "    for neuron in self.layers[0]:\n",
        "      neuron['output'] = sigmoid(np.dot(data, neuron['weights']) + neuron['bias'])\n",
        " \n",
        "    hid_array = [neuron['output'] for neuron in self.layers[0]]\n",
        "    \n",
        "    # Hidden ke output\n",
        "    for neuron in self.layers[1]:\n",
        "      neuron['output'] = sigmoid(np.dot(hid_array, neuron['weights']) + neuron['bias'])\n",
        "    \n",
        "    out_array = [neuron['output'] for neuron in self.layers[1]]\n",
        " \n",
        "    return out_array\n",
        " \n",
        "  # Backward propagate\n",
        "  # Pertama delta tiap output neuron dicari dengan rumus\n",
        "  # delta = (aktivasi - prediksi) * aktivasi * (1 - aktivasi)\n",
        "  # kemudian bobot hidden -> output diupdate pake rumus\n",
        "  # nwe_weight = old_weight - learn_rate*delta*\n",
        "  def backward(self, data, output, target, learn_rate):\n",
        "      delta_array_out = []\n",
        "      # output ke hidden\n",
        "      ## cari delta tiap output neuron\n",
        "      for index, neuron in enumerate(self.layers[1]):\n",
        "        delta = (neuron['output'] - target[index]) * neuron['output'] * (1 - neuron['output'])\n",
        "        delta_array_out.append(delta)\n",
        "      \n",
        "      ## update bobot axon dari hidden ke output\n",
        "      for index, neuron in enumerate(self.layers[1]):\n",
        "        new_weights = [neuron['weights'][i] - (learn_rate * delta_array_out[index] * self.layers[0][i]['output']) for i in range(len(neuron['weights']))]\n",
        "        neuron['weights'] = new_weights\n",
        "        neuron['bias'] = neuron['bias'] - learn_rate * delta_array_out[index]\n",
        "      \n",
        "      \n",
        "      delta_array_hid = []\n",
        "      # hidden ke input\n",
        "      ## cari delta tiap hidden neuron\n",
        "      for index, neuron in enumerate(self.layers[0]):\n",
        "        inweight = [neur['weights'][index] for neur in self.layers[1]]\n",
        "        potential = np.dot(inweight, delta_array_out)\n",
        "        delta = potential * neuron['output'] * (1 - neuron['output'])\n",
        "        delta_array_hid.append(delta)\n",
        "      \n",
        "      ## update bobot axon dari input ke hidden\n",
        "      for index, neuron in enumerate(self.layers[0]):\n",
        "        new_weights = [neuron['weights'][i] - (learn_rate * delta_array_hid[index] * data[i]) for i in range(len(neuron['weights']))]\n",
        "        neuron['weights'] = new_weights\n",
        "        neuron['bias'] = neuron['bias'] - learn_rate * delta_array_hid[index]\n",
        "   \n",
        " \n",
        "  def train(self, dataset, labels, epochs = 1, learn_rate = 0.5):\n",
        "    errors = []\n",
        "    accuracies = []\n",
        "    for i in range(epochs):\n",
        "      error = 0\n",
        "      correct = 0\n",
        "      print('Training epoch', i + 1, '...')\n",
        "      for data, label in zip(dataset, labels):\n",
        "        #print('data:', *data)\n",
        "        out_array = self.forward(data)\n",
        "        if(out_array.index(max(out_array)) == label):\n",
        "          correct += 1\n",
        "        label_array = [1 if i == label else 0 for i in range(len(self.layers[1]))]\n",
        "        error += mse(out_array, label_array)\n",
        "        self.backward(data, out_array, label_array, learn_rate)\n",
        "      print('Error:', error, '\\n')\n",
        "      errors.append(error)\n",
        "      accuracies.append(correct / len(dataset))\n",
        "    \n",
        "    print('Training done')\n",
        " \n",
        "    return errors, accuracies\n",
        "  \n",
        "  def test(self, dataset, labels):\n",
        "    print('Testing start...\\n')\n",
        "    correct = 0\n",
        "    for data, label in zip(dataset, labels):\n",
        "      output = self.forward(data)\n",
        "      prediction = output.index(max(output))\n",
        "      print('predicted', prediction, 'should be', label, end = '')\n",
        "      if(prediction == label):\n",
        "        print('....ok')\n",
        "        correct += 1\n",
        "      else:\n",
        "        print('....miss')\n",
        "    \n",
        "    return correct / len(dataset)\n",
        "  \n",
        "  def predict(self, dataset):\n",
        "    predictions = []\n",
        "    for data in dataset:\n",
        "      output = self.forward(data)\n",
        "      prediction = output.index(max(output))\n",
        "      predictions.append(prediction)\n",
        "    \n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPXmOFOzuj4l"
      },
      "source": [
        "## Fetch data and parsing Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwBW_AP-p4WA"
      },
      "source": [
        "# Return 2 buah list isi dataset:\n",
        "# list pertama adalah dataset (X) berupa ndarray\n",
        "# list kedua adalah labelnya (y) berupa ndarray\n",
        "# bisa langsung jadi parameter buat test_train_split()\n",
        "def load_data():\n",
        "  path = '/content/drive/Shareddrives/Machine Learning/flowers'\n",
        "  flowers = os.listdir(path)\n",
        "  print(flowers)\n",
        "\n",
        "  label = dict(zip(flowers, [0, 1, 2]))\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for folder in flowers:\n",
        "    images = os.listdir(os.path.join(path, folder))\n",
        "    X.extend([resize(\n",
        "                grayscale(\n",
        "                    cv2.imread(os.path.join(path, folder, image))\n",
        "                    ),\n",
        "                    320,\n",
        "                    240\n",
        "                ) for image in images])\n",
        "    y.extend([label[folder]] * len(images))\n",
        "  \n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yazb-NGhuWlD"
      },
      "source": [
        "###Image and data Transform Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_mfh5F2sqoq"
      },
      "source": [
        "def resize(img, height, width):\n",
        "  return cv2.resize(img,(height, width), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "def grayscale(img):\n",
        "  return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOP0PMvZSwaW"
      },
      "source": [
        "# ubah ke 1 dimensi\n",
        "def flatten(data):\n",
        "  '''\n",
        "  Flatten\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  X: list(list()) `Data input layer 2 dimensi hanya 1 data`\n",
        "\n",
        "  Return\n",
        "  ------\n",
        "  X_new: list() `Data dijadikan 1 dimensi`\n",
        "  '''\n",
        "  np_data = np.array(data)\n",
        "  return np_data.flatten()\n",
        "\n",
        "# ubah data ke range 0 - 1\n",
        "def normalize(data):\n",
        "  '''\n",
        "  Normalize\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  X: list() `Data input layer 1 dimensi hanya 1 data`\n",
        "\n",
        "  Return\n",
        "  ------\n",
        "  X_new: list() `Data dijadikan antara 0 dan 1`\n",
        "  '''\n",
        "  np_data = np.array(data)\n",
        "  return np_data/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p46w-RsguufK"
      },
      "source": [
        "##Load Shared Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaK0sCccutcF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evfz_Lefy4or"
      },
      "source": [
        "# sudah dilakukan grayscale dan resize\n",
        "data_img, data_label = load_data()\n",
        "\n",
        "# show image\n",
        "cv2_imshow(data_img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTctANldS-3e"
      },
      "source": [
        "# Ubah ke 1 dimensi\n",
        "# Data dijadikan range 0 sampai 1\n",
        "data_normal = []\n",
        "for img in data_img:\n",
        "  flat = flatten(img)\n",
        "  normal = normalize(flat)\n",
        "  data_normal.append(normal)\n",
        "\n",
        "# Split data train & test\n",
        "x_train, x_test, y_train, y_test = train_test_split(data_normal, data_label, train_size=0.8)\n",
        "x_train, y_train = shuffle(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leeCi0xDu0Yk"
      },
      "source": [
        "###Defining Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FRy36OjTc_F"
      },
      "source": [
        "input_length = len(x_train[0])\n",
        "hidden_length = len(x_train[0]) + 100\n",
        "output_length = max(y_train)\n",
        "\n",
        "# Init network\n",
        "network = Network(input_length, hidden_length, output_length)\n",
        "\n",
        "# Training\n",
        "errors, accuracy = network.train(X_train, y_train, epochs = 50, learn_rate = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhdlG3KXUjx3"
      },
      "source": [
        "# plot errors and accuracy\n",
        "plt.plot(errors, color = 'r')\n",
        "plt.title('Error per Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAfsB1BZUoCs"
      },
      "source": [
        "plt.plot(accuracy, color = 'g')\n",
        "plt.title('Accuracy per Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly4zR6-XUrVj"
      },
      "source": [
        "# TEST\n",
        "accuracy = network.test(X_test, y_test)\n",
        "print('Test Accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}